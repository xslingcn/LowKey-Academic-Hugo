---
type: publications
title: "Attention Is All You Need"
draft: false
date: 2017-06-12T09:16:45.000Z
selected: true
image: transformer.png
description: "A new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely is proposed, which generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."
authors: "Ashish Vaswani, **Noam M. Shazeer**, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin"
venue: "NeurIPS 2017"
pdf: https://arxiv.org/abs/1706.03762
code: https://github.com/hyunwoongko/transformer
website: https://en.wikipedia.org/wiki/Attention_Is_All_You_Need
categories:
  - Research
tags:
  - Machine Learning
---

A new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely is proposed, which generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.